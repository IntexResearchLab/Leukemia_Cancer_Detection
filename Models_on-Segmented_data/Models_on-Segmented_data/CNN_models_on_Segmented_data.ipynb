{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guAVW8Lnt0yG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
        "from keras.applications import MobileNetV2, VGG16, DenseNet121\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define image dimensions\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/train_test_val/train',\n",
        "                                                    target_size=(img_height, img_width),\n",
        "                                                    batch_size=16,\n",
        "                                                    class_mode='binary')\n",
        "val_generator = val_datagen.flow_from_directory('/content/drive/MyDrive/train_test_val/val',\n",
        "                                                target_size=(img_height, img_width),\n",
        "                                                batch_size=16,\n",
        "                                                class_mode='binary')\n",
        "test_generator = test_datagen.flow_from_directory('/content/drive/MyDrive/train_test_val/test',\n",
        "                                                 target_size=(img_height, img_width),\n",
        "                                                 batch_size=16,\n",
        "                                                 class_mode='binary',\n",
        "                                                 shuffle=False)\n",
        "\n",
        "# Define checkpoint\n",
        "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "\n",
        "########################################\n",
        "# MobileNetV2 Model\n",
        "########################################\n",
        "mobilenet_v2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "for layer in mobilenet_v2.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = GlobalAveragePooling2D()(mobilenet_v2.output)\n",
        "x = Dropout(0.5)(x)\n",
        "prediction = Dense(1, activation='sigmoid')(x)\n",
        "model1 = Model(inputs=mobilenet_v2.input, outputs=prediction)\n",
        "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history1 = model1.fit(train_generator, validation_data=val_generator, epochs=20, callbacks=[checkpoint])\n",
        "model1.save('/content/drive/MyDrive/model/mobileNetV2_ensemble_model.h5')\n",
        "\n",
        "# Plot MobileNetV2\n",
        "plt.plot(history1.history['accuracy'], label='Train')\n",
        "plt.plot(history1.history['val_accuracy'], label='Validation')\n",
        "plt.title('MobileNetV2 Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history1.history['loss'], label='Train')\n",
        "plt.plot(history1.history['val_loss'], label='Validation')\n",
        "plt.title('MobileNetV2 Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "########################################\n",
        "# VGG16 Model\n",
        "########################################\n",
        "vgg_16 = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "for layer in vgg_16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(vgg_16.output)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "prediction = Dense(1, activation='sigmoid')(x)\n",
        "model2 = Model(inputs=vgg_16.input, outputs=prediction)\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history2 = model2.fit(train_generator, validation_data=val_generator, epochs=30, callbacks=[checkpoint])\n",
        "\n",
        "# Plot VGG16\n",
        "plt.plot(history2.history['accuracy'], label='Train')\n",
        "plt.plot(history2.history['val_accuracy'], label='Validation')\n",
        "plt.title('VGG16 Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history2.history['loss'], label='Train')\n",
        "plt.plot(history2.history['val_loss'], label='Validation')\n",
        "plt.title('VGG16 Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "########################################\n",
        "# DenseNet121 Model\n",
        "########################################\n",
        "densenet = DenseNet121(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "densenet.trainable = False\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(densenet)\n",
        "model3.add(GlobalAveragePooling2D())\n",
        "model3.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model3.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history3 = model3.fit(train_generator, validation_data=val_generator, epochs=20, verbose=2, callbacks=[early_stopping])\n",
        "model3.save('/content/drive/MyDrive/Colab Notebooks/train_test_val/Dense121_64_model.h5')\n",
        "\n",
        "# Plot DenseNet121\n",
        "plt.plot(history3.history['accuracy'], label='Train')\n",
        "plt.plot(history3.history['val_accuracy'], label='Validation')\n",
        "plt.title('DenseNet121 Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history3.history['loss'], label='Train')\n",
        "plt.plot(history3.history['val_loss'], label='Validation')\n",
        "plt.title('DenseNet121 Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ]
}